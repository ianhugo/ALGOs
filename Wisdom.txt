Algorithms set developers apart
Algorithms are everywhere.

Algorithms are a specific set of clearly
defined instructions
aimed to carry out a task or process (fast)

Algorithms involve
creative, elegant ways to implement a solution
creative and efficient use of data structures

Algorithms allow one to peek
under the hood of SQL and Linux commands

Algorithms are about performance
an algorithm is a technology

Algorithms are
compact and simple pieces of logic, 
working perfectly to perform a single task

Donald Knuth:
father of analysis of algorithms
“People who analyze algorithms have double happiness. 
First of all they experience the sheer beauty of elegant 
mathematical patterns that surround computational procedures. 
Then they receive a practical payoff when their theories make 
it possible to get other jobs done more quickly and economically.”

LESSONS from the field:
- always reclarify the problem
- work with a few examples
- note down the different goals/milestones
- try a brute force
- plan out functions before implement
- anchor problems in patterns (confidence)
- have structure to thinking
- sorted input?

Observation 1:
An approach might not work completely
But that does not mean abandon immediately
It might be a half way solution
Note down what it solves
Note down what it is lacking
Breaking down problems into smaller ones

Observation 2: (esp DP)
Try to reduce outcomes into cases
Where other cases collapse to these cases
Draw a line in the sand then adjust

Observation 3:
have multiple thoughts
sketch out what happens
why it would or won't work
what is missing

Observation 4:
What are the implications/corollories of this result?

Observation 5:
Clean up after hacking
Be sure to think of edge cases!

Observation 6:
Approach it with mathematical thinking
Play and engage with the problem to start
Make useful observations
Entry -> Specializing -> Attack -> Generalizing -> Reviewing

Observation 7: 
Simplify cases with max-ing, min-ing

Observation 8:
If need sorting or preprocessing
Using a data struct might be "free"

Observation 9:
don't compromise accuracy/logic of solution
for faster time and smaller space

Observation 10 Merge Intervals:
- use minheap to do sorting of one layer (one subset of things) (sorting time smaller) (heap cheese)
- abstract the characteristic of the gap: between current_end, next_start

Observation 11 Cyclic Sort:
Cyclic sort movement through array, if duplicate, creates a cycle
as go to same "correct" position more than once

Observation 12 Cyclic Sort:
Can skip over negatives, and skip over numbers larger than length

Observation 13:
Having recognized a potential pattern
It still might not fit the cookie mould
Might have to preprocess to fit the pattern
Skip over things, change things and such

Observation 14: dirty hacky solution
If O(1) space, but need a hash map
Use a "hash_str" with n zeros
"00000"
"10000" index 0 is present

Observation 15 Cyclic Sort:
If don't want to modify
Iterate over array, when meet number
mark presence of a number, by changing its relevant index to -ve
Iterate again to find missing numbers, where elements are positive

Observation 16:
Know to modulus stuff when iterations will cycle in some way

Observation 17 Recursion:
State base cases, situations to return
at each level, do preprocessing, then pass down
When pass down, note if need to change values
hit base level, recursion unwinds
at each level, do post processing, then pass up
Unwinding = chain of returns

Observation 18 Recursion:
The function is self spawning little minions/workers
Each with the same logic
Each looking for the base case
Each explores a level
if not base case, spawn more minions
then when find base case, recurse backwards

Observation 18.1 Recursion 2:
What is done to pre-process? What to check? What action to take? Base cases?
What the next locations to check are? What recursive calls?
What is passed down? What values? What containers? 
How do recursive calls relate? One after another? Take stat measure of results? Compute?

Observation 19 Heaps in Python:
- python heapq is a minheap
- so if want maxheap, push in negatives

Observation 20 Subset pattern:
- take note of what choice needs to be made at each level
- permutation = place at each position . . .
- do some examples

Observation 21 Subset pattern:
- there are two patterns
- 1: make a copy of everything, apply changes to a copy of it
    - number of items have doubled
- 2: apply changes to all of them, where possible]

Observation 22 Subset pattern:
- apply changes based on condition
- apply different types of changes
- apply each change to all last states

Observation 23:
do try/except
don't expect users not to mess things up (input validation)
simplify, generalize, scalable

Observation 24: (DP Target Sum)
- when recognize pattern
- but want to implement hacky, complicated scheme
- try to math it out a bit first
- see if can convert the question to a familiar form

Observation 25: DP
- overlapping subproblems, optimal substructure
- means need to consider all combinations (all possible, but cut in a certain way)
- but check if already computed
- and store after computing
- and store a running optimized solution/value (sometimes)

Observation 26: DP Top-Down
- start with the whole problem
- with recursion
- do DFS on one branch all the way
- store solutions

Observation 27: DP Bottom-Up
- start with smallest version of problem
- same goal, but with less "candidates"
- keep expanding until have full list of candidates

Observation 28: DP table
- always a good anchor 
- separate into at least two ways of slicing
- (two strings, start-end, weight-object, attribute1-attribute2)
- (but is not to all DP problems, for example fib patterns)

Observation 29: stacks
- like building a cake
- partial layers on top (227_basic_calc)
- might want to swap out a layer (31_next_permute)
- queue or stack can store a partial state, then wiped as well (1762_buildings)